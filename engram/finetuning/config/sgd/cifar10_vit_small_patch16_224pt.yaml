# python -m engram.train --config engram/finetuning/config/sgd/cifar10_vit_small_patch16_224pt.yaml
model: cifar_vit_small_patch16_224
pretrained: true
num_classes: 10
opt: sgd
lr: 0.001
sched: cosine
epochs: 50
lr_min: 0
warmup_lr: 0.00001
warmup_epochs: 5
t_in_epochs: true
batch_size: 100
data_path: './data'
seed: 42
output: './result/cifar10_vit_small_patch16_224pt_sgd'
